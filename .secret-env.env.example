# LiteLLM Proxy Environment Variables
# Copy this file to .secret-env.env and fill in your actual values

# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_API_BASE=https://api.openai.com/v1

# Anthropic API Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_API_BASE=https://api.anthropic.com

# Google AI API Configuration
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_APPLICATION_CREDENTIALS=path/to/your/service-account-key.json

# Azure OpenAI Configuration
AZURE_API_KEY=your_azure_openai_key_here
AZURE_API_BASE=https://your-resource.openai.azure.com/
AZURE_API_VERSION=2023-12-01-preview

# AWS Bedrock Configuration
AWS_ACCESS_KEY_ID=your_aws_access_key_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_key_here
AWS_REGION_NAME=us-east-1

# Cohere API Configuration
COHERE_API_KEY=your_cohere_api_key_here

# Hugging Face API Configuration
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Ollama Configuration (for local models)
OLLAMA_API_BASE=http://localhost:11434

# Proxy Server Configuration
LITELLM_PROXY_PORT=8000
LITELLM_PROXY_HOST=0.0.0.0
LITELLM_MASTER_KEY=your_master_key_here

# Database Configuration
DATABASE_URL=sqlite:///litellm_proxy.db

# Logging Configuration
LITELLM_LOG_LEVEL=INFO
LITELLM_SET_VERBOSE=false

# Security Configuration
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8080"]
MAX_REQUEST_SIZE=10485760

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000

# Cache Configuration
REDIS_URL=redis://localhost:6379
CACHE_TTL=3600
